{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import urllib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ROOT_DIR = os.path.abspath('.')\n",
    "\n",
    "QUERY_URL = 'http://www.iwencai.com/data-robot/search?qs=pc_~soniu~stock~resultpage~datarobot~zdjgy&query=%s&isChatBot=0&direct_mode=[\"iwencai\"]'\n",
    "QUERY_COLUMN = [\n",
    "    '股票代码', '股票简称', '收盘价不复权', '收盘价前复权', '收盘价后复权', '总市值', '流通市值', '市净率', '市盈率',\n",
    "    '市销率', '市现率', '成交额', '成交量', '股本', '每股净资产', '净资产收益率', '总资产', '净资产', '负债',\n",
    "    '货币资金', '营业收入', '净利润', '未分配利润', '营业收入增长率', '资产负债率', '毛利率', '申万行业', '证监会行业',\n",
    "    '同花顺行业', '上市时间'\n",
    "]\n",
    "\n",
    "STATISTIC_COLUMN = [\n",
    "    '收盘价不复权', '收盘价前复权', '收盘价后复权', '总市值', '流通市值', '市净率', '市盈率', '市销率', '市现率',\n",
    "    '成交额', '成交量', '股本', '每股净资产', '净资产收益率', '总资产', '净资产', '负债', '货币资金', '营业收入',\n",
    "    '净利润', '未分配利润', '营业收入增长率', '资产负债率', '毛利率'\n",
    "]\n",
    "\n",
    "CLASSICFICATION = [\n",
    "    '采掘', '传媒', '电气设备', '电子', '房地产', '纺织服装', '非银金融', '钢铁', '公用事业', '国防军工',\n",
    "    '化工', '机械设备', '计算机', '家用电器', '建筑材料', '建筑装饰', '交通运输', '农林牧渔', '汽车', '轻工制造',\n",
    "    '商业贸易', '食品饮料', '通信', '休闲服务', '医药生物', '银行', '有色金属', '综合'\n",
    "]\n",
    "\n",
    "DATA_DIR = ROOT_DIR + '\\\\data'\n",
    "BASIC_DATA_DIR = DATA_DIR + '\\\\basic'\n",
    "STOCK_DATA_DIR = DATA_DIR + '\\\\stock'\n",
    "TRADE_DATE_FILE = DATA_DIR + '\\\\date_week.txt'\n",
    "ALL_STOCK_FILE = DATA_DIR + '\\\\stock.data'\n",
    "STATISTIC_FILE = DATA_DIR + '\\\\statistic.data'\n",
    "CLASSIFIED_FILE = DATA_DIR + '\\\\classified.data'\n",
    "MARKET = ['全部市场', '上海市场', '深圳市场', '创业板市场']\n",
    "METHOD = ['count', 'std', 'min', '25%', '50%', '75%', 'max', 'mean', 'sum']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 同花顺问财iwencai数据机器人数据导出\n",
    "\n",
    "## 数据访问方式\n",
    "\n",
    "http://www.iwencai.com/data-robot/search?qs=pc_~soniu~stock~resultpage~datarobot~zdjgy&query=%s&isChatBot=0&direct_mode=[\"iwencai\"]\n",
    "\n",
    "* 这个查询接口曾经出现过一段时间，现在已经在问财网站上找不到公开的调用\n",
    "\n",
    "关键在于查询问句query，比如 “今年创新低的股票”，“2011.1.1 股价，PB”...\n",
    "\n",
    "返回的是json格式\n",
    "\n",
    "\n",
    "## 主要思路\n",
    "\n",
    "### 用途\n",
    "\n",
    "用于导出个股历史数据，形成本地的基础数据库，以便于保存 统计 查询 等功能\n",
    "\n",
    "导出频率以一周为一个数据快照\n",
    "\n",
    "### 功能\n",
    "#### get_Snapshot(date,  query)\n",
    "Parameters：\n",
    "date   查询快照日期\n",
    "query  查询快照问句\n",
    "\n",
    "Return:\n",
    "返回查询结果dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_Snapshot(date, query):\n",
    "    qstr = pd.Series(query)\n",
    "    request = QUERY_URL % urllib.parse.quote(qstr.str.cat(sep='[%s],' % date))\n",
    "    try:\n",
    "        response = urllib.request.urlopen(request)\n",
    "    except urllib.error.URLError as e:\n",
    "        print(e.reason)\n",
    "    j_data = json.loads(response.read())\n",
    "    ss = pd.DataFrame(j_data['data']['result'])\n",
    "    ss.columns = QUERY_COLUMN\n",
    "    ss = ss.dropna(subset=['上市时间'])\n",
    "    ss = ss[ss['上市时间'] <= date]\n",
    "    ss = ss.reset_index(drop=True)\n",
    "    ss = ss.fillna(0)\n",
    "    for col in STATISTIC_COLUMN:\n",
    "        ss[col] = ss[col].astype(float)\n",
    "    return ss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save_Snapshot(snapshot, filename)\n",
    "用Pickle方式序列化snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_Snapshot(snapshot, filename, overwrite=True):\n",
    "    if os.path.exists(filename) and not overwrite:\n",
    "        print('已存在该数据文件%s.' % filename)\n",
    "        return False\n",
    "    else:\n",
    "        return snapshot.to_pickle(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load_Snapshot(filename)\n",
    "读取snapshot\n",
    "\n",
    "Parameters:\n",
    "\n",
    "filename snapshot文件\n",
    "\n",
    "Return:\n",
    "\n",
    "返回dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_Snapshot(filename):\n",
    "    if not os.path.exists(filename):\n",
    "        print('不存在该数据文件%s.' % filename)\n",
    "        return False\n",
    "    else:\n",
    "        return pd.read_pickle(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def date_to_str(date):\n",
    "    d = date.split('/', 3)\n",
    "    return '%04d%02d%02d' % (int(d[0]), int(d[1]), int(d[2]))\n",
    "\n",
    "\n",
    "def get_TradeDate():\n",
    "    filename = TRADE_DATE_FILE\n",
    "    if os.path.exists(filename):\n",
    "        wd = pd.read_table(filename, encoding='utf-8', header=None)\n",
    "        return wd\n",
    "    else:\n",
    "        print('不存在该日期文件%s.' % filename)\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### build_local_Snapshot(start_end, query)\n",
    "查询需要的问句，并保存到本地，形成本地数据库。一个文件代表一天的数据快照。\n",
    "\n",
    "Parameters：\n",
    "\n",
    "start_end    查询开始结束时间，是一个日期list\n",
    "\n",
    "query        查询问句"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_local_Snapshot(start_end, query):\n",
    "    print('正在重建本地基础数据库(交易日快照)，耗时比较长，请耐心等候！', end='')\n",
    "\n",
    "    total = len(start_end)\n",
    "    i = 0\n",
    "    # 下载基础数据库，一个date，一个数据文件\n",
    "    for date in start_end:\n",
    "        filename = '%s/%s.data' % (BASIC_DATA_DIR, date_to_str(date))\n",
    "        if not os.path.exists(filename):\n",
    "            ss = get_Snapshot(date, query)\n",
    "            save_Snapshot(ss, filename)\n",
    "\n",
    "        print('[本地基础数据库(交易日快照)] 数据处理中(%d/%d)' % (i, total), end='')\n",
    "        i += 1\n",
    "    print('重建本地基础数据库(交易日快照)完毕！', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#build_local_Snapshot(get_TradeDate()[0], QUERY_COLUMN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### build_stock_Snapshot()\n",
    "将下载的每天数据快照，全部整合成一个数据快照，方便做一些中间的计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_stock_Snapshot():\n",
    "    print('正在重建整合数据，耗时比较长，请耐心等候！', end='')\n",
    "    stock = pd.DataFrame()\n",
    "\n",
    "    for filenames in os.listdir(BASIC_DATA_DIR):\n",
    "        i = 0\n",
    "        total = len(filenames)\n",
    "        # 根据下载的基础数据库，全部整合到一个数据文件\n",
    "        for filename in filenames:\n",
    "            fname = os.path.splitext(filename)\n",
    "            # 格式化时间 yyyy-MM-dd\n",
    "            date = fname[0]\n",
    "            ss = load_Snapshot('%s/%s' % (BASIC_DATA_DIR, filename))\n",
    "            ss['date'] = date\n",
    "            stock = stock.append(pd.DataFrame(ss))\n",
    "            print('[整合数据] 数据处理中(%d/%d)' % (i, total), end='')\n",
    "            i += 1\n",
    "    # NaN 用 0 填充\n",
    "    stock = stock.fillna(0)\n",
    "    save_Snapshot(stock, ALL_STOCK_FILE)\n",
    "    print('重建本地整合数据完毕！', end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split_stock_Snapshot()\n",
    "把整合全部的数据快照，按照股票代码切割出来。形成一个文件是一个股票历史数据快照。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_stock_Snapshot():\n",
    "    print('正在重建本地基础数据库(个股快照)，耗时比较长，请耐心等候！', end='')\n",
    "    if not os.path.exists(ALL_STOCK_FILE):\n",
    "        build_stock_Snapshot()\n",
    "    else:\n",
    "        stock = load_Snapshot(ALL_STOCK_FILE)\n",
    "        stk = stock.drop_duplicates(subset=['股票代码'], keep='first')\n",
    "        i = 0\n",
    "        total = len(stk)\n",
    "        # 将切割成一个股票，一个历史文件\n",
    "        for code in stk['股票代码']:\n",
    "            s = stock[stock['股票代码'].str.contains(code)]\n",
    "            s = s.reset_index(drop=True)\n",
    "\n",
    "            filename = '%s/%s.data' % (STOCK_DATA_DIR, code.split('.', 2)[0])\n",
    "            save_Snapshot(s, filename)\n",
    "            print('[本地基础数据库(个股快照)] 数据处理中(%d/%d)' % (i, total), end='')\n",
    "            i += 1\n",
    "    print('重建本地基础数据库(个股快照)完毕！', end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### build_statistic_Snapshot()\n",
    "对每天的数据快照做一个统计计算，并合并成一个统计数据快照。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_statistic_Snapshot():\n",
    "    print('正在重建个股统计数据，耗时比较长，请耐心等候！', end='')\n",
    "    statistic = pd.DataFrame()\n",
    "\n",
    "    for filenames in os.listdir(BASIC_DATA_DIR):\n",
    "        i = 0\n",
    "        total = len(filenames)\n",
    "        for filename in filenames:\n",
    "            fname = os.path.splitext(filename)\n",
    "            # 格式化时间 yyyy-MM-dd\n",
    "            date = fname[0]\n",
    "            ss = load_Snapshot('%s/%s' % (BASIC_DATA_DIR, filename))\n",
    "\n",
    "            # 全市场统计\n",
    "            desc = ss.describe()\n",
    "\n",
    "            desc.loc['sum'] = ss.sum()\n",
    "            desc['date'] = date\n",
    "            desc['market'] = '全部市场'\n",
    "            statistic = statistic.append(pd.DataFrame(desc))\n",
    "\n",
    "            # 上海市场统计\n",
    "            dt = ss[ss['股票代码'].str.contains(r'^6')]\n",
    "            desc = dt.describe()\n",
    "            desc.loc['sum'] = dt.sum()\n",
    "            desc['date'] = date\n",
    "            desc['market'] = '上海市场'\n",
    "            statistic = statistic.append(pd.DataFrame(desc))\n",
    "\n",
    "            # 深圳市场统计\n",
    "            dt = ss[ss['股票代码'].str.contains(r'^0')]\n",
    "            desc = dt.describe()\n",
    "            desc.loc['sum'] = dt.sum()\n",
    "            desc['date'] = date\n",
    "            desc['market'] = '深圳市场'\n",
    "            statistic = statistic.append(pd.DataFrame(desc))\n",
    "\n",
    "            # 创业板市场统计\n",
    "            dt = ss[ss['股票代码'].str.contains(r'^3')]\n",
    "            desc = dt.describe()\n",
    "            desc.loc['sum'] = dt.sum()\n",
    "            desc['date'] = date\n",
    "            desc['market'] = '创业板市场'\n",
    "            statistic = statistic.append(pd.DataFrame(desc))\n",
    "            print('[个股统计] 数据处理中(%d/%d)' % (i, total), end='')\n",
    "            i += 1\n",
    "    # NaN 用 0 填充\n",
    "    statistic = statistic.fillna(0)\n",
    "    save_Snapshot(statistic, STATISTIC_FILE)\n",
    "    print('重建个股统计数据完毕！', end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### build_classified_Snapshot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def build_classified_Snapshot():\n",
    "    print('正在重建行业统计数据，耗时比较长，请耐心等候！', end='')\n",
    "    statistic = pd.DataFrame()\n",
    "    for filenames in os.listdir(BASIC_DATA_DIR):\n",
    "        i = 0\n",
    "        total = len(filenames)\n",
    "\n",
    "        for filename in filenames:\n",
    "            fname = os.path.splitext(filename)\n",
    "            # 格式化时间 yyyy-MM-dd\n",
    "            date = fname[0]\n",
    "            ss = load_Snapshot('%s/%s' % (BASIC_DATA_DIR, filename))\n",
    "\n",
    "            # Groupby 行业\n",
    "            ss['行业'] = ss['申万行业'].apply(lambda x: x.split('-')[0])\n",
    "            ss['date'] = date\n",
    "            dt = ss.groupby(['date', '行业'])\n",
    "            desc = dt.agg([\n",
    "                'count', 'std', 'min', ('25%',\n",
    "                                        lambda x: pd.Series.quantile(x, .25)),\n",
    "                ('50%', lambda x: pd.Series.quantile(x, .5)),\n",
    "                ('75%',\n",
    "                 lambda x: pd.Series.quantile(x, .75)), 'max', 'mean', 'sum'\n",
    "            ])\n",
    "            desc = desc.reset_index()\n",
    "            statistic = statistic.append(pd.DataFrame(desc))\n",
    "            print('[行业统计] 数据处理中(%d/%d)' % (i, total), end='')\n",
    "            i += 1\n",
    "    # NaN 用 0 填充\n",
    "    statistic = statistic.fillna(0)\n",
    "    save_Snapshot(statistic, CLASSIFIED_FILE)\n",
    "    print('重建行业统计数据完毕！', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#build_classified_Snapshot()\n",
    "#build_statistic_Snapshot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "654px",
    "left": "1546px",
    "right": "20px",
    "top": "242px",
    "width": "342px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
